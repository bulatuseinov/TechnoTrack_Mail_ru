{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ae714f57-c941-4390-b512-4221211bd0e6"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "__ Для опытов над моделями удобно использовать библиотеку для pytorch - torchvision __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "23bfc1fc-b4dd-428c-9cf7-e0ae58aa82d5"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from IPython.core.display import display, HTML, Markdown\n",
    "import math\n",
    "from operator import mul\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 123456789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123,456,789\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:,}\".format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "993a860f-85a5-4c53-8964-2eefd438246d"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Вспомогательная функция для печати\n",
    "def html_print(List):\n",
    "    out = ''\n",
    "    \n",
    "    for Text, Data in List:\n",
    "        f_str = '{1:,}' if type(Data) == int else '{1}'\n",
    "        if len(out) > 0: out += ', ' \n",
    "        out += (\"<font size=6>{0}</font> <font color=blue size=6> \"+f_str).format(Text, Data) + \"</font><br>\"\n",
    "    display(HTML(out))\n",
    "    \n",
    "def display_gif(fn):\n",
    "    from IPython import display\n",
    "    return display.HTML('<img src=\"{}\">'.format(fn))\n",
    "    \n",
    "def print_size(text, size_vec, float_size=4):\n",
    "    res = \"%d bytes \" % float_size\n",
    "    total = 4\n",
    "    for item_size in size_vec:\n",
    "        res += 'x%d' % item_size\n",
    "        total *= item_size\n",
    "    res += \"={0:,}\".format(total)\n",
    "    html_print([(text, res)])\n",
    "    \n",
    "def print_sizes(Text, Sizes):\n",
    "    size = '' \n",
    "    for s in Sizes:\n",
    "        l = \"%d\"%s[0]\n",
    "        for ss in s[1:]:\n",
    "            l += 'x%d'%ss\n",
    "            \n",
    "        if len(size) > 0: size += ' + '\n",
    "        size += l\n",
    "        \n",
    "    html_print([(Text,size)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue>Как понять какая сеть \"круче\"?</font>\n",
    "\n",
    "## MNIST\n",
    "---\n",
    "THE MNIST DATABASE of handwritten digits\n",
    "\n",
    "Yann LeCun, Courant Institute, NYU\n",
    "\n",
    "Corinna Cortes, Google Labs, New York\n",
    "\n",
    "Christopher J.C. Burges, Microsoft Research, Redmond\n",
    "\n",
    "#### Изображения цифр от 0 до 9 в черно-белом виде размера 28x28\n",
    "\n",
    "train 60 000, test 10 000\n",
    "\n",
    "![MnistExamples.png](attachment:MnistExamples.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 (100)\n",
    "\n",
    "The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. \n",
    "\n",
    "They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n",
    "\n",
    "\n",
    "Картинки из 10 классов и 100 подклассов размером 32x32x3\n",
    "\n",
    "50 000 train, 10 000 test\n",
    "\n",
    "![cifar10_example.png](attachment:cifar10_example.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet\n",
    "\n",
    "###  Large Scale Visual Recognition Challenge (ILSVRC) - 1000 classes\n",
    "\n",
    "train 1 200 000, test 150 000\n",
    "\n",
    "Total number of images: 14,197,122 (на сегодня)\n",
    "\n",
    "Средний размер картинок в ImageNet 469x387 pix, обычно приводят к 256x256 и кропают до 224x224 - но даже 224x224 в 50 раз больше CIFAR по кол-ву пикселей\n",
    "\n",
    "\n",
    "\n",
    "![imagenet_example.jpg](attachment:imagenet_example.jpg)\n",
    "\n",
    "![Screenshot%20from%202018-10-17%2020-04-46.png](attachment:Screenshot%20from%202018-10-17%2020-04-46.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bd994109-fd08-43a8-a495-fef77402af6e"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font size=10 color=blue>LeNet</font>\n",
    "### _ [LeCun et al., 1998] _\n",
    "---\n",
    "![LeNet](./img/lenet.png)\n",
    "\n",
    "<font size=5>\n",
    "* Конволюции:  фильтры 5x5, страйд 1 <br/><br/>\n",
    "* Сабсамплинг aka пулиг:  фильтры 2x2 , страйд 2 <br/><br/>\n",
    "* Архитектура: [CONV-POOL-CONV-POOL-FC-FC]\n",
    "\n",
    "</font>\n",
    "---\n",
    "\n",
    "\n",
    "#### Одна из первых конволюционных сетей - выбила хорошие результаты на MNIST\n",
    "![mnist_lenet.gif](attachment:mnist_lenet.gif)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue> LSVRC-2017 </font>\n",
    "![imagenet_results.png](attachment:imagenet_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "21bb4bca-732c-4b4c-8848-53fac30d3b9a"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <font size=10 color=blue>AlexNet</font> \n",
    "### _ [Krizhevsky et al. 2012] _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8487f843-9969-4968-a244-cd6e5ceaeeb3"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![alexnet_kuzma.png](attachment:alexnet_kuzma.png)\n",
    "![AlexNet](img/alexnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "49639861-3403-4f98-a80a-9a8395acb0a9"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<font size='5'> В 2012 году решение на основе AlexNet выиграло соревнование ILSVRC'12 (ImageNet)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d8551909-4de7-4768-98e3-b750586a6c29"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <font color=blue size=8>AlexNet - архитектура </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet. \n",
    "\n",
    "The first work that popularized Convolutional Networks in Computer Vision was the AlexNet, developed by Alex Krizhevsky, Ilya Sutskever and Geoff Hinton. The AlexNet was submitted to the ImageNet ILSVRC challenge in 2012 and significantly outperformed the second runner-up (top 5 error of 16% compared to runner-up with 26% error). The Network had a very similar architecture to LeNet, but was deeper, bigger, and featured Convolutional Layers stacked on top of each other (previously it was common to only have a single CONV layer always immediately followed by a POOL layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "240a6b20-79d9-4d38-91ff-ee8e83bb4d99"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_net = models.AlexNet()\n",
    "alex_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что же такое dilation у Conv2d и MaxPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./gifs/dilation.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_gif(\"./gifs/dilation.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# На что тратятся ресурсы при работе с нейросетями\n",
    "## 1. Параметры сетки\n",
    "## 2. Промежуточное представление изображения (тензора)\n",
    "## 3. Вычисления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "979d4d85-faaa-4ed0-a0bd-120283a4a602"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=blue size=10> AlexNet - первый слой</font>\n",
    "Через свойство _ features _ получаем доступ к конволюционным слоям. Через свойство _ classifier _ доступ к FC слоям\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "e3c3cea8-397e-46e1-94d6-199e591ee243"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Свертка первого слоя:  <br></font> <font color=blue size=6> Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CONV1 = alex_net.features[0]\n",
    "html_print([( \"Свертка первого слоя:  <br>\", CONV1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "724e2b08-9285-48c1-a151-f62f04cb3538"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Размер входного изображения <font color=blue>224x224</font>\n",
    "Количество каналов изображение можно получить через in_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "7dff99b5-c1c9-4dcd-9fb7-ccdac2d1348e"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Количество каналов изображения: </font> <font color=blue size=6> 3</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_print([(\"Количество каналов изображения: \", CONV1.in_channels)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5d8b0226-396e-4193-93cc-9cd6a9609665"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "### Размер конволюции:\n",
    "<br>Получаем размер конволюции через свойства\n",
    "* kernel_size - размер ядра\n",
    "* stride      - шаг\n",
    "* out_channels - количество выходных каналов\n",
    "* padding      - паддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "db2d1a55-5ea6-48c8-bff4-61d5f2879a06"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Размер ядра: </font> <font color=blue size=6> 11x11</font><br>, <font size=6>Выходных панелей: </font> <font color=blue size=6> 64</font><br>, <font size=6>Шаг: </font> <font color=blue size=6> 4x4</font><br>, <font size=6>=> Итого: </font> <font color=blue size=6> 64x11x11, stride: 4</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_print([( 'Размер ядра: ', \"%d\" % CONV1.kernel_size[0] + \"x%d\" % CONV1.kernel_size[1] ),\n",
    "            ( 'Выходных панелей: ', \"%d\" % CONV1.out_channels ),\n",
    "            ( \"Шаг: \", \"%d\" % CONV1.stride[0] +  \"x%d\" % CONV1.stride[1] ),\n",
    "            ( \"=> Итого: \",\"{0}x{1}x{2}, stride: {3}\".format(CONV1.out_channels,\n",
    "               CONV1.kernel_size[0], CONV1.kernel_size[1], CONV1.stride[0]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fa936582-9e45-4590-8356-81ea80631852"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color=red size=6>В: Какое количество параметров слоя?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "d86e1861-59dd-4193-b17a-09396fcf7011"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Размер тензора параметров: </font> <font color=blue size=6> 3x11x11x96</font><br>, <font size=6>Количество параметров: </font> <font color=blue size=6> 34848</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# В оригинальной статье было 96 фильтров https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "html_print([(\"Размер тензора параметров: \", \"{0}x{1}x{2}x{3}\".format(3,11,11,96)),\n",
    "            (\"Количество параметров: \", \"{0}\".format(3*11*11*96))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=6>В: Какой размер выхода?</font>\n",
    "<br>Если мы знаем, что: <br>\n",
    "$$H_{out} = floor((H_{in}  + 2 * padding[0] - kernel\\_size[0]) / stride[0] + 1)$$\n",
    "$$W_{out} = floor((W_{in}  + 2 * padding[1] - kernel\\_size[1]) / stride[1] + 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$$ H_{out}=55 $$ "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$$ W_{out}=55 $$ "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hout = math.floor((224+2*CONV1.padding[0]-CONV1.kernel_size[0])/CONV1.stride[0]+1)\n",
    "Wout = math.floor((224+2*CONV1.padding[1]-CONV1.kernel_size[1])/CONV1.stride[1]+1)\n",
    "display(Markdown( \"$$ H_{out}=%d $$ \"%Hout ))\n",
    "display(Markdown( \"$$ W_{out}=%d $$ \"%Wout ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbpresent": {
     "id": "759b05a9-3e0d-4d5f-be90-8e4518551e95"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Размер выходного слоя: </font> <font color=blue size=6> 96x55x55</font><br>, <font size=6>=> Размер выходного слоя в байтах: </font> <font color=blue size=6> 1161600</font><br>, <font size=6>=> Размер выходного слоя в мегабайтах: </font> <font color=blue size=6> 1.108</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Размер float=4 байта\n",
    "html_print([( \"Размер выходного слоя: \", \"{0}x{1}x{2}\".format(96,55,55)),\n",
    "            (\"=> Размер выходного слоя в байтах: \", \"{0}\".format(96*55*55*4)),\n",
    "            (\"=> Размер выходного слоя в мегабайтах: \", \"{:.3f}\".format(96*55*55*4/1024/1024))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=4>В: Расходуется ли какое-то еще дополнительное место при backward?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=6>В: Сколько вычислительных операций на первом слое?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FLOPS - кол-во операций с float (с плавающей запятой) в секунду\n",
    "\n",
    "### 2012 год\n",
    "\n",
    "GTX 580 3 Gb - 1 581 GFLOPS (1 581 000 000 000)\n",
    "\n",
    "AMD FX-8350 4,1 ГГц, 8 ядер (2012) — 184 Гфлопса[40]\n",
    "\n",
    "Intel Core i7-4930K (Ivy Bridge), частоты 3,7-4,2 ГГц, 6 ядер (2013) — 130—140 гигафлопсов (теоретический пик 177 GFlops)\n",
    "\n",
    "### История\n",
    "\n",
    "Intel 80486DX/DX2 (1990—1992) — до 30-50 мегафлопсов[31]\n",
    "\n",
    "Intel Pentium 75-200 МГц (1996) — до 75-200 мегафлопсов[31][32]\n",
    "\n",
    "Intel Pentium III 450—1133 МГц (1999—2000) — до 450—1113 Мфлопсов[31][32]\n",
    "\n",
    "Intel Pentium III-S (2001) 1ГГц — 1,4 ГГц — до 1 — 1,4 Гфлопса[32]\n",
    "\n",
    "Intel Atom N270, D150 1,6 ГГц (2008—2009) — до 3,2 Гфлопса[31]\n",
    "\n",
    "Intel Pentium 4 2,5-2,8 ГГц (2004) — до 5 — 5,6 Гфлопса[31]\n",
    "\n",
    "AMD Athlon 64 X2 4200+ 2,2 ГГц (2006) — 8,8 Гфлопса\n",
    "\n",
    "Intel Core 2 Duo E6600 2,4 ГГц, 2 ядра (2006) — 19,2 Гфлопса[33]\n",
    "\n",
    "МЦСТ Эльбрус-4С (1891ВМ8Я) 800 МГц, 4 ядра (2014) — пиковая производительность 25 Гфлопсов (двойной точности, 50 Гфлопсов одинарной точности)[34]\n",
    "\n",
    "Intel Core i3-2350M 2,3 ГГц, 2 ядра (2011) — 36,8 Гфлопса[35]\n",
    "\n",
    "Intel® Core™2 Quad Q6600 2,40 ГГц, 4 ядра (2007) — 38,4 Гфлопса[36]\n",
    "\n",
    "Intel Core 2 Quad Q8300 2,5 ГГц, 4 ядра (2008) — 40 Гфлопсов[37]\n",
    "\n",
    "AMD Athlon II X4 640 3,0 ГГц, 4 ядра (2010) — 48 Гфлопсов\n",
    "\n",
    "Intel Core i7-975 XE (Nehalem) 3,33 ГГц, 4 ядра (2009) — 53,3 гигафлопса[38]\n",
    "\n",
    "AMD Phenom II X4 965 BE 3,4 ГГц, 4 ядра (2009) — 54,4 Гфлопса\n",
    "\n",
    "AMD Phenom II X6 1100T 3,3 ГГц , 6 ядер (2010) — 79,2 Гфлопса\n",
    "\n",
    "Intel Core i5-2500K (Sandy Bridge), частоты 3,3-3,7 ГГц (2011) — 105,6-118 гигафлопсов[39]\n",
    "\n",
    "AMD FX-8350 4,1 ГГц, 8 ядер (2012) — 184,6 Гфлопса[40]\n",
    "\n",
    "Intel Core i7-4930K (Ivy Bridge), частоты 3,7-4,2 ГГц, 6 ядер (2013) — 130—140 гигафлопсов (теоретический пик 177 GFlops)\n",
    "Loongson-3B1500 (MIPS64), 1,5 ГГц, 8 ядер (2016) — до 192 ГФлопсов.[41]\n",
    "\n",
    "МЦСТ Эльбрус-8СВ 1,5 ГГц, 8 ядер (планируется 2018)[42] — пиковая производительность 576 Гфлопсов -(Предположительно), (288 Гфлопсов двойной точности).[43]\n",
    "\n",
    "Intel Core i7-5960X (Extreme Edition Haswell-E), частоты 3,0-3,5 ГГц (2014) — до 350 гигафлопсов (теоретический пик 384 ГФлопса)[44]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Кол-во опервций : кол-во параметров * выходной размер</font> <font color=blue size=6> 34848x3025=105,415,200</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Кол-во опервций : кол-во параметров * выходной размер * batch_size </font> <font color=blue size=6> 34848x3025x128=13,493,145,600</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_print([( \"Кол-во опервций : кол-во параметров * выходной размер\", \"{0}x{1}={2:,}\".format(34848,55*55,34848*55*55))])\n",
    "html_print([( \"Кол-во опервций : кол-во параметров * выходной размер * batch_size \", \n",
    "             \"{0}x{1}x{2}={3:,}\".format(34848,55*55,128, 34848*55*55*128))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9c53eb4c-ecef-47d0-855c-edb8f18be86c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "___\n",
    "# <font color=blue size=10> AlexNet - второй слой</font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# На что тратятся ресурсы при работе с нейросетями\n",
    "## 1. Параметры сетки\n",
    "## 2. Промежуточное представление изображения (тензора)\n",
    "## 3. Вычисления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "07c9f399-1ef6-4fac-8f65-0448eccc03af"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Пулинг: <br></font> <font color=blue size=6> MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "POOL1=alex_net.features[2]\n",
    "html_print([(\"Пулинг: <br>\", POOL1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d60fb6e4-b096-421a-9c34-79d41eeef7cd"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color=red size=6>В: Количество параметров пулинг слоя?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbpresent": {
     "id": "f753c88c-d584-4bdf-9d6e-8329e8b1aa13"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Параметров в пулинг слое: </font> <font color=blue size=6> 0</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_print([(\"Параметров в пулинг слое: \", \"{0}\".format(0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=6>Формула для рассчета выхода пулинг слоя</font>\n",
    "$$H_{out} = floor((H_{in}  + 2 * padding[0] - dilation[0] * (kernel\\_size[0] - 1) - 1) / stride[0] + 1)$$\n",
    "$$W_{out} = floor((W_{in}  + 2 * padding[1] - dilation[1] * (kernel\\_size[1] - 1) - 1) / stride[1] + 1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "52625045-43c1-40b9-a460-c6bf3afc3682"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Размерность выхода второго слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "01834b53-10cc-41f6-8097-436f6448ac2c"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Вход пулинг слоя: </font> <font color=blue size=6> 4 bytes x96x55x55=1,161,600</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Выход пулинг слоя: </font> <font color=blue size=6> 4 bytes x96x27x27=279,936</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# генерируем тензор по размеру выхода первого слоя, пропускаем его через второй  слой\n",
    "POOL1_IN = torch.rand(96, 55, 55)\n",
    "POOL1_OUT = POOL1(POOL1_IN)\n",
    "print_size(\"Вход пулинг слоя: \", POOL1_IN.size() )\n",
    "print_size(\"Выход пулинг слоя: \", POOL1_OUT.size() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=3>В: Почему картинка уменьшилась вдвое, а размер в 4 раза?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=6>В: Сколько вычислительных операций на втором слое?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629,856\n"
     ]
    }
   ],
   "source": [
    "#кол-во параметров MaxPool2d=0 , а вот вычислений сколько?\n",
    "print(\"{:,}\".format(3*3*96*27*27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# <font color=blue size=10> AlexNet - full connected 6</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alex_net.features[0] = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2)\n",
    "# alex_net.features[1] = nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2)\n",
    "# alex_net.features[6] = nn.Conv2d(256, 384, kernel_size=5, stride=1, padding=1)\n",
    "# alex_net.features[8] = nn.Conv2d(384, 384, kernel_size=5, stride=1, padding=1)\n",
    "# alex_net.features[10] = nn.Conv2d(384, 256, kernel_size=5, stride=1, padding=1)\n",
    "\n",
    "# test_input = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "# alex_net.features\n",
    "\n",
    "# alex_net.features(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer = alex_net.classifier[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=9216, out_features=4096, bias=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params 37,748,736\n",
      "Params in memory 150,994,944\n",
      "Params in memory with backword and adam 603,979,776\n"
     ]
    }
   ],
   "source": [
    "#1 параметры , еще +1 за bias\n",
    "total_params = layer.in_features * layer.out_features\n",
    "print(\"Params {:,}\".format(total_params))\n",
    "print(\"Params in memory {:,}\".format(total_params*4))\n",
    "#храним мат.ожидания и дисперсии параметров и производные\n",
    "print(\"Params in memory with backword and adam {:,}\".format(total_params*4*4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "# Выходной размер - мизернй\n",
    "print(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate operations 37,748,736\n"
     ]
    }
   ],
   "source": [
    "# Вычислений - по кол-ву весов тупо\n",
    "print(\"Calculate operations {:,}\".format(total_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# <font color=blue size=7> Relu</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU() ReLU(inplace)\n"
     ]
    }
   ],
   "source": [
    "## 1. Параметры сетки\n",
    "## 2. Промежуточное представление изображения (тензора)\n",
    "## 3. Вычисления\n",
    "\n",
    "a = nn.ReLU(inplace=False)\n",
    "b = nn.ReLU(inplace=True)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7a40228a-b38d-4b5f-a72d-9364a787241d"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font size=10 color=blue>AlexNet</font> \n",
    "### _ [Krizhevsky et al. 2012] _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "750c9e2a-9edb-49b1-ace4-a174a35685dd"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### _ Полная архитектура: _\n",
    "<div style='font-size:20px'>\n",
    "<pre>\n",
    "[227x227x3] INPUT \n",
    "[55x55x96]  <font color=red>CONV1: </font> 96x11x11 filters at stride 4, pad 0 \n",
    "[27x27x96]  <font color=blue>MAX POOL1:</font> 3x3 filters at stride 2\n",
    "[27x27x96]  <font color=green>NORM1:</font> Normalization layer \n",
    "[27x27x256] <font color=red>CONV2:</font> 256 5x5 filters at stride 1, pad 2 \n",
    "[13x13x256] <font color=blue>MAX POOL2:</font> 3x3 filters at stride 2 \n",
    "[13x13x256] <font color=green>NORM2:</font> Normalization layer \n",
    "[13x13x384] <font color=red>CONV3:</font> 384 3x3 filters at stride 1, pad 1 \n",
    "[13x13x384] <font color=red>CONV4:</font> 384 3x3 filters at stride 1, pad 1 \n",
    "[13x13x256] <font color=red>CONV5:</font> 256 3x3 filters at stride 1, pad 1 \n",
    "[6x6x256]   <font color=blue>MAX POOL3:</font> 3x3 filters at stride 2 \n",
    "[4096] <font color=brown>FC6:</font> 4096 neurons \n",
    "[4096] <font color=brown>FC7:</font> 4096 neurons \n",
    "[1000] <font color=brown>FC8:</font> 1000 neurons (class scores)\n",
    "</pre>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3dc9b4b4-0709-493c-b5d7-d3b93d132ddc"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### _ Детали: _\n",
    "- Первое использование ReLU \n",
    "- Использование  Norm layers (не прижилось)  \n",
    "- Data augmentation \n",
    "- Dropout 0.5 \n",
    "- Batch size 128 \n",
    "- SGD Momentum 0.9 \n",
    "- Learning rate 1e-2, уменьшали в 10 раз руками, при насыщении\n",
    "- L2 weight decay 5e-4 \n",
    "- 7 CNN в ансамбле: 18.2% -> 15.4%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b91020bf-46f8-45d6-971e-671135c36183"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![AlexNet](img/alexnet01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "579bf115-dcf3-4688-ae5a-a2b961d1e51b"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### _ История: _\n",
    "<div style='font-size:20px; padding:10px; color:blue'>\n",
    "Тренировали на GTX 580 GPU, память 3 GB .  Сеть разделили на 2 GPU, по половине на нейронов на каждый.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c5bc43d7-f8cb-4630-b559-fd423b1f0933"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![AlexNet](./img/alexnet03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "da1d5f0f-0706-47c3-9421-d874a4e18185"
    }
   },
   "source": [
    "<div style='font-size:20px; padding:10px; color:blue'>\n",
    "CONV1, CONV2, CONV4, CONV5: Соединятся только карты признаков на одной GPU\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "399c7dac-db77-4946-a693-884587f29b5d"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![AlexNet](img/alexnet02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7cfc3649-70d1-4845-b95f-4ca658e15cd3"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div style='font-size:20px; padding:10px; color:blue'>\n",
    "CONV3, FC6, FC7, FC8: Соединятся карты признаков с предшествующим слоем между GPU\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "255f2ee6-b728-42d9-aa1c-b5a8e09cfa4f"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font size=10 color=blue> Победители ImageNet Large Scale Visual Recognition Challenge (LSVRC) \n",
    "</font>\n",
    "![ImageNet](./img/ImageNetGraph01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "76400926-921d-433e-96e2-d10052b90b88"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font size=10 color=blue> LSVRC-2013</font>\n",
    "![ImageNet](./img/ImageNetGraph02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font size=10 color=blue>ZFNet</font> \n",
    "### _ [Zeiler and Fergus, 2013] _\n",
    "![ZNet](./img/ZNet.png)\n",
    "<div style='font-size:20px; padding:10px; color:blue'>\n",
    "<pre>\n",
    "AlexNet но:\n",
    "CONV1: изменили с (11x11 stride 4) на (7x7 stride 2) \n",
    "CONV3,4,5: вместо 384, 384, 256 фильтров использовали 512, 1024, 512 \n",
    "\n",
    "<font color=blue>ImageNet top 5 error: 16.4% -> 11.7%</font>\n",
    "</pre>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font size=10 color=blue> VGGNet </font>\n",
    "### _ [Simonyan and Zisserman, 2014] _\n",
    "* VGG11\n",
    "* VGG13\n",
    "* VGG16\n",
    "* VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font  color=blue> VGG11 + PyTorch </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU(inplace)\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU(inplace)\n",
       "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU(inplace)\n",
       "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (12): ReLU(inplace)\n",
       "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (14): ReLU(inplace)\n",
       "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): ReLU(inplace)\n",
       "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (19): ReLU(inplace)\n",
       "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg = models.vgg11()\n",
    "vgg.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Dropout(p=0.5)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace)\n",
       "  (5): Dropout(p=0.5)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    " ![VGGNet01](./img/VGG01.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " * <font color=red>Меньшие фильтры, Сети глубже </font> \n",
    " <font color=blue>\n",
    " * 8 слоев (AlexNet) -> 16 - 19 слоев (VGG16Net)\n",
    " * Используем только 3x3 CONV stride 1, pad 1 and  2x2 MAX POOL stride 2\n",
    " * 11.7% top 5 error в ILSVRC’13 (ZFNet) -> 7.3% top 5 error в ILSVRC’14\n",
    " </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color=red size=6>\n",
    "<br>\n",
    " В: Зачем использовать небольшие (3x3) фильтры?\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<font color=red size=6>\n",
    "<br>\n",
    "\n",
    " В: Какое эффективное рецептивное поле  \n",
    " \n",
    " у трех конволюционных слоев с конволюцией 3x3 (stride 1)?\n",
    " \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![ConvSobel](./img/convSobel.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    " * Стэк из трех слоев с конволюциями 3x3 (stride 1)  имеет такое же рецептивное поле как один слой с конволюцией 7x7\n",
    " * Глубже, больше нелинейностей\n",
    " * Меньше параметров: $$ 3 * (3^2*С^2) = 27*C^2 $$ vs. $$ 7^2*С^2=49*C^2 $$ где C - количество каналов на слой, то <b>есть почти в два раза меньше параметров</b>\n",
    " \n",
    " Почему $ C^2 $ ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### В Nvidia в cuDNN после выхода сети VGG специально оптимизировали работу конволюций размером 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# небольшой код по подсчету памяти и количества параметров в сети\n",
    "MODULES_STAT=[]\n",
    "\n",
    "def module_forward_hook(module, input, output):\n",
    "    weight = module.weight.size() if not isinstance(module, torch.nn.modules.MaxPool2d) else (0, 0, 0, 0)\n",
    "    MODULES_STAT.append((module, output.size(), weight))\n",
    "    \n",
    "def setup_vgg_hooks(vgg):\n",
    "    for f in vgg.features: \n",
    "        if type(f) == torch.nn.modules.conv.Conv2d or type(f) == torch.nn.modules.MaxPool2d :\n",
    "            f.register_forward_hook(module_forward_hook)\n",
    "            \n",
    "    for f in vgg.classifier:\n",
    "        if type(f) == torch.nn.modules.Linear:\n",
    "            f.register_forward_hook(module_forward_hook)\n",
    "            \n",
    "def calc_memory(input_size):\n",
    "    res = 1\n",
    "    for i in input_size: res *= i\n",
    "        \n",
    "    suffix = 'Kb'\n",
    "    res /= 1024\n",
    "    \n",
    "    if res > 1024:\n",
    "        res /= 1024\n",
    "        suffix = 'Mb'\n",
    "    if res > 1024:\n",
    "        res /= 1024\n",
    "        suffix = 'Gb'\n",
    "        \n",
    "    return \"%0.2f %s\" % (res, suffix)\n",
    "                 \n",
    "def features_mem_and_params(vgg, input_tenzor):\n",
    "    _ = vgg(input_tenzor) #Делаем прогон, чтобы вычислить один раз все hooks\n",
    "    input_size = input_tenzor.size()\n",
    "    total_param = 0\n",
    "    total_mem =  reduce(mul,(input_size))\n",
    "    print( \"%02d\" % 0,\n",
    "          'INPUT',\n",
    "          \"memory\",\n",
    "          \"%dx%dx%d=%s\" % (input_size[0], input_size[1], input_size[2], calc_memory(input_size)),\n",
    "          \"parameters\", \"%dx%dx%d=%d\" % (0, 0, 0 , 0)\n",
    "         ) \n",
    "    for i, stat in enumerate(MODULES_STAT):\n",
    "        module_name = str(stat).split('(')[1]\n",
    "        total_param += reduce(mul,(stat[2]))\n",
    "        total_mem   += reduce(mul,(stat[1]))\n",
    "        \n",
    "        if 'Linear' in module_name:\n",
    "            print( \"%02d\"%(i+1),'FC',\"memory\", \"%dx%d=%s \"% (stat[1][0], stat[1][1], calc_memory(stat[1]) ),\n",
    "               \"parameters\", \"%dx%d=%d\"%(stat[2][0], stat[2][1] , reduce(mul,(stat[2]))))\n",
    "        else:    \n",
    "            print( \"%02d\"%(i+1),module_name,\"memory\", \"%dx%dx%d=%s\" % (stat[1][1], stat[1][2], stat[1][3], calc_memory(stat[1])),\n",
    "               \"parameters\", \"%dx%dx%dx%d=%d\"%(stat[2][0], stat[2][1], stat[2][2], stat[2][3] , reduce(mul,(stat[2]))))\n",
    "    print()\n",
    "    print (\"Total_mem: %d * 4 = %d\" % (total_mem, total_mem * 4))\n",
    "    print (\"Total params: %d\" % total_param, \"Total_mem: %d\" % total_mem)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# берем модель VGG-16 \n",
    "vgg = models.vgg16()\n",
    "# это хук для дампа информации\n",
    "setup_vgg_hooks(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 INPUT memory 1x3x224=147.00 Kb parameters 0x0x0=0\n",
      "01 Conv2d memory 64x224x224=3.06 Mb parameters 64x3x3x3=1728\n",
      "02 Conv2d memory 64x224x224=3.06 Mb parameters 64x64x3x3=36864\n",
      "03 MaxPool2d memory 64x112x112=784.00 Kb parameters 0x0x0x0=0\n",
      "04 Conv2d memory 128x112x112=1.53 Mb parameters 128x64x3x3=73728\n",
      "05 Conv2d memory 128x112x112=1.53 Mb parameters 128x128x3x3=147456\n",
      "06 MaxPool2d memory 128x56x56=392.00 Kb parameters 0x0x0x0=0\n",
      "07 Conv2d memory 256x56x56=784.00 Kb parameters 256x128x3x3=294912\n",
      "08 Conv2d memory 256x56x56=784.00 Kb parameters 256x256x3x3=589824\n",
      "09 Conv2d memory 256x56x56=784.00 Kb parameters 256x256x3x3=589824\n",
      "10 MaxPool2d memory 256x28x28=196.00 Kb parameters 0x0x0x0=0\n",
      "11 Conv2d memory 512x28x28=392.00 Kb parameters 512x256x3x3=1179648\n",
      "12 Conv2d memory 512x28x28=392.00 Kb parameters 512x512x3x3=2359296\n",
      "13 Conv2d memory 512x28x28=392.00 Kb parameters 512x512x3x3=2359296\n",
      "14 MaxPool2d memory 512x14x14=98.00 Kb parameters 0x0x0x0=0\n",
      "15 Conv2d memory 512x14x14=98.00 Kb parameters 512x512x3x3=2359296\n",
      "16 Conv2d memory 512x14x14=98.00 Kb parameters 512x512x3x3=2359296\n",
      "17 Conv2d memory 512x14x14=98.00 Kb parameters 512x512x3x3=2359296\n",
      "18 MaxPool2d memory 512x7x7=24.50 Kb parameters 0x0x0x0=0\n",
      "19 FC memory 1x4096=4.00 Kb  parameters 4096x25088=102760448\n",
      "20 FC memory 1x4096=4.00 Kb  parameters 4096x4096=16777216\n",
      "21 FC memory 1x1000=0.98 Kb  parameters 1000x4096=4096000\n",
      "\n",
      "Total_mem: 15237608 * 4 = 60950432\n",
      "Total params: 138344128 Total_mem: 15237608\n"
     ]
    }
   ],
   "source": [
    "test_pic = torch.rand(1, 3, 224, 224)\n",
    "MODULES_STAT = []   \n",
    "features_mem_and_params(vgg, test_pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOTAL memory: 15M \\* 4 bytes ~= 60MB / image (прямой проход! \\~\\*2 для bwd) <br/>\n",
    "TOTAL params: 138M parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<pre>\n",
    "00 INPUT memory 1x3x224=150528 parameters 0x0x0=0\n",
    "<font color=red>01 Conv2d memory 64x224x224=3211264 parameters 64x3x3x3=1728      <<== больше всего памяти \n",
    "02 Conv2d memory 64x224x224=3211264 parameters 64x64x3x3=36864</font>\n",
    "03 MaxPool2d  memory 64x112x112=802816 parameters 0x0x0x0=0\n",
    "04 Conv2d memory 128x112x112=1605632 parameters 128x64x3x3=73728\n",
    "05 Conv2d memory 128x112x112=1605632 parameters 128x128x3x3=147456\n",
    "06 MaxPool2d  memory 128x56x56=401408 parameters 0x0x0x0=0\n",
    "07 Conv2d memory 256x56x56=802816 parameters 256x128x3x3=294912\n",
    "08 Conv2d memory 256x56x56=802816 parameters 256x256x3x3=589824\n",
    "09 Conv2d memory 256x56x56=802816 parameters 256x256x3x3=589824\n",
    "10 MaxPool2d  memory 256x28x28=200704 parameters 0x0x0x0=0\n",
    "11 Conv2d memory 512x28x28=401408 parameters 512x256x3x3=1179648\n",
    "12 Conv2d memory 512x28x28=401408 parameters 512x512x3x3=2359296\n",
    "13 Conv2d memory 512x28x28=401408 parameters 512x512x3x3=2359296\n",
    "14 MaxPool2d  memory 512x14x14=100352 parameters 0x0x0x0=0\n",
    "15 Conv2d memory 512x14x14=100352 parameters 512x512x3x3=2359296\n",
    "16 Conv2d memory 512x14x14=100352 parameters 512x512x3x3=2359296\n",
    "17 Conv2d memory 512x14x14=100352 parameters 512x512x3x3=2359296\n",
    "18 MaxPool2d  memory 512x7x7=25088 parameters 0x0x0x0=0\n",
    "<font color=blue>19 FC memory 1x4096=4096 parameters 4096x25088=102760448      <<== больше всего параметров </font>\n",
    "20 FC memory 1x4096=4096 parameters 4096x4096=16777216\n",
    "21 FC memory 1x1000=1000 parameters 1000x4096=4096000\n",
    "\n",
    "Total_mem: 15237608 * 4 = 60950432\n",
    "Total params: 138344128 Total_mem: 15237608\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![VGG](./img/VGG02.png)\n",
    "<center><font color=blue>Общие названия слоев VGG</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Детали:\n",
    "- ILSVRC’14 второе место в классификации, первое в локализации\n",
    "- Процедура тренировки такая же как у AlexNet\n",
    "- Нет Local Response Normalisation (LRN)\n",
    "- Для решения использовались только VGG16 or VGG19\n",
    "- Использовали ансамбли для лучших результатов\n",
    "- FC7 фичи можно использовать для решения других задач\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font size=10 color=blue> LSVRC-2014 </font>\n",
    "![ImageNet](./img/ImageNetGraph03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font size=10 color=blue> GooLeNet </font>\n",
    "_ [Szegedy et al., 2014] _\n",
    "![ImageNet](./img/Inception01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![ImageNet](./img/Inception02.png)\n",
    "<center> <font size=5 color=blue> Модуль Inception </font> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 22 слоя\n",
    "- Эффективный модуль “Inception”\n",
    "- Нет полносвязных слоев\n",
    "- 5 миллионов параметров! в 12x раз меньше чем AlexNet\n",
    "- ILSVRC’14 победитель в классификации (6.7% top 5 error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Идея рассмотреть картинку в различных разрешениях => наивный Inseption модуль, который видит картинку в разных разрешениях.\n",
    "- Множественные фильты (1x1, 3x3, 5x5)\n",
    "- Оперраци пулинга (3x3)\n",
    "\n",
    "![ImageNet](./img/Inception03.png)\n",
    "<center> <font size=5 color=blue> Наивный модуль Inception </font> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class NaiveInception(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels):\n",
    "        super(NaiveInception, self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, 128, 1, 1)\n",
    "        self.conv3x3 = nn.Conv2d(in_channels, 192, 3, 1, 1)\n",
    "        self.conv5x5 = nn.Conv2d(in_channels, 96, 5, 1, 2)\n",
    "        self.pool3x3 = nn.MaxPool2d(3, 1, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        o1x1 = self.conv1x1(input)\n",
    "        o3x3 = self.conv3x3(input)\n",
    "        o5x5 = self.conv5x5(input)\n",
    "        op3x3 = self.pool3x3(input)\n",
    "  \n",
    "        return torch.cat( (o1x1,o3x3,o5x5, op3x3), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Размер входа = </font> <font color=blue size=6> 4 bytes x1x256x28x28=802,816</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = torch.rand(1, 256, 28, 28)\n",
    "print_size(\"Размер входа = \", input.size())\n",
    "# ---\n",
    "naiveInception = NaiveInception(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def print_output_size(out):\n",
    "    html_print ([(\"Размер выхода слоя: \",\"%dx%dx%dx%d\"%out.size()), ( \" количество фич: \", reduce(mul, out.size()))])\n",
    "\n",
    "def params_size(conv):\n",
    "    sizes = []\n",
    "    for param in conv.parameters():\n",
    "        if len(param.size()) == 1: continue # skip bias\n",
    "        sizes.append( [ s for s in param.size() ] )\n",
    "    return sizes \n",
    "\n",
    "def num_elems(ss):\n",
    "    num = 0\n",
    "    for s in ss: num += reduce(mul, s )\n",
    "    return num\n",
    "\n",
    "def print_inception_param_stat(net):\n",
    "    print_sizes(\"Conv1x1 = \", params_size( net.conv1x1) )\n",
    "    print_sizes(\"Conv3x3 = \", params_size( net.conv3x3) )\n",
    "    print_sizes(\"Conv5x5 = \", params_size( net.conv5x5) )\n",
    "    html_print([(\"Pool3x3 = \", 0)])\n",
    "    html_print([(\"Всего параметров = \", num_elems( params_size(net.conv1x1) )+ \n",
    "                                    num_elems( params_size( net.conv3x3) ) + \n",
    "                                    num_elems( params_size( net.conv5x5)) )])\n",
    "    \n",
    "def expand_dims(add_dims, or_dims):\n",
    "    result = []\n",
    "    for i, dim in enumerate(or_dims):\n",
    "        a = add_dims[i] if i < len(add_dims) else []\n",
    "        result.append(a + dim)\n",
    "    return result\n",
    "    \n",
    "def print_inception_param_ops(net):\n",
    "    in_dims = [[28, 28], [28, 28]]\n",
    "    print_sizes(\"Conv1x1 = \", expand_dims(in_dims, params_size(net.conv1x1))  )\n",
    "    print_sizes(\"Conv3x3 = \", expand_dims(in_dims, params_size(net.conv3x3)))\n",
    "    print_sizes(\"Conv5x5 = \", expand_dims(in_dims, params_size(net.conv5x5)))\n",
    "    html_print([(\"Pool3x3 = \", 0)])\n",
    "    html_print([(\"Всего операций свертки = \", \n",
    "                                    num_elems(expand_dims(in_dims, params_size(net.conv1x1)))+ \n",
    "                                    num_elems(expand_dims(in_dims, params_size(net.conv3x3))) +\n",
    "                                    num_elems(expand_dims(in_dims, params_size(net.conv5x5))) )])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=5 color=red>В: Каков размер выходного слоя?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Размер выхода слоя: </font> <font color=blue size=6> 1x672x28x28</font><br>, <font size=6> количество фич: </font> <font color=blue size=6> 526,848</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = naiveInception(input)\n",
    "print_output_size(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=5 color=red>В: Количество параметров?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Conv1x1 = </font> <font color=blue size=6> 128x256x1x1</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Conv3x3 = </font> <font color=blue size=6> 192x256x3x3</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Conv5x5 = </font> <font color=blue size=6> 96x256x5x5</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Pool3x3 = </font> <font color=blue size=6> 0</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Всего параметров = </font> <font color=blue size=6> 1,089,536</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_inception_param_stat(naiveInception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=5 color=red>В: Количество операций свертки?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Conv1x1 = </font> <font color=blue size=6> 28x28x128x256x1x1</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Conv3x3 = </font> <font color=blue size=6> 28x28x192x256x3x3</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Conv5x5 = </font> <font color=blue size=6> 28x28x96x256x5x5</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Pool3x3 = </font> <font color=blue size=6> 0</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Всего операций свертки = </font> <font color=blue size=6> 854,196,224</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_inception_param_ops(naiveInception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font size=10 color=blue> Уменьшаем размерность </font>\n",
    "![ImageNet](./img/Inception04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Решение: добавим дополнительные слои, которые будут выполнять уменьшение размерности.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Inception](./img/Inception05.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346816512\n",
      "99549184\n"
     ]
    }
   ],
   "source": [
    "print(256*28*28*192*3*3)\n",
    "print(256*28*28*64*1 + 64*28*28*192*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, reduce_features=64):\n",
    "        super(Inception, self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, 128, 1, 1)\n",
    "        self.conv3x3 = nn.Sequential ( nn.Conv2d(in_channels, reduce_features, 1, 1),\n",
    "                                       nn.Conv2d(reduce_features, 192, 3, 1, 1) )\n",
    "        self.conv5x5 = nn.Sequential ( nn.Conv2d(in_channels, reduce_features, 1, 1), \n",
    "                                       nn.Conv2d(reduce_features, 96, 5, 1, 2))\n",
    "        self.pool3x3 = nn.Sequential ( nn.MaxPool2d(3, 1, 1), \n",
    "                                       nn.Conv2d(in_channels, reduce_features, 1, 1))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        o1x1 = self.conv1x1(input)\n",
    "        o3x3 = self.conv3x3(input)\n",
    "        o5x5 = self.conv5x5(input)\n",
    "        op3x3 = self.pool3x3(input)\n",
    "  \n",
    "        return torch.cat( (o1x1,o3x3,o5x5, op3x3), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Размер выхода слоя: </font> <font color=blue size=6> 1x480x28x28</font><br>, <font size=6> количество фич: </font> <font color=blue size=6> 376,320</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inception = Inception(256)\n",
    "out_inc = inception(input)\n",
    "print_output_size(out_inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=5 color=red>В: Количество параметров?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Conv1x1 = </font> <font color=blue size=6> 128x256x1x1</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Conv3x3 = </font> <font color=blue size=6> 64x256x1x1 + 192x64x3x3</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Conv5x5 = </font> <font color=blue size=6> 64x256x1x1 + 96x64x5x5</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Pool3x3 = </font> <font color=blue size=6> 0</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Всего параметров = </font> <font color=blue size=6> 329,728</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_inception_param_stat(inception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font size=5 color=red>В: Количество операций свертки?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<font size=6>Conv1x1 = </font> <font color=blue size=6> 28x28x128x256x1x1</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Conv3x3 = </font> <font color=blue size=6> 28x28x64x256x1x1 + 28x28x192x64x3x3</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Conv5x5 = </font> <font color=blue size=6> 28x28x64x256x1x1 + 28x28x96x64x5x5</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Pool3x3 = </font> <font color=blue size=6> 0</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=6>Всего операций свертки = </font> <font color=blue size=6> 258,506,752</font><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_inception_param_ops(inception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue> GooLeNet </font>\n",
    "_ [Szegedy et al., 2014] _\n",
    "![ImageNet](./img/Inception06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Более глубокая сеть с вычислительной эффективностью\n",
    "- 22 слоя с весами\n",
    "- Эффективный модуль “Inception”\n",
    "- Нет тяжелых FC слоев\n",
    "- 12x раз меньше параметров чем в AlexNet\n",
    "- победитель в ILSVRC’14 \n",
    "_ (6.7% top 5 error) _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue> LSVRC-2014 </font>\n",
    "![ImageNet](./img/ImageNetGraph05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font size=10 color=blue> ResNet </font>\n",
    "### _ [He et al., 2015] _\n",
    "![ImageNet](./img/ResNet01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Основной элемент - Residual block\n",
    "![ResNet](./img/ResNet02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень глубокая сеть, которая использует shortcut соединения\n",
    "- 152-слойная сеть для ImageNet\n",
    "- ILSVRC’15 - победитель (3.57% top 5 error)\n",
    "- Победила во всех классификациях и соревнования по детекции ILSVRC’15 and COCO’15!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ResNet](./img/ResNet03.png)\n",
    "<font size=5 color=red>В: что произойдет если мы увеличим глубину VGG19?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ResNet](./img/ResNet04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Гипотеза: проблема обучения это проблема _ оптимизации _ , чем глубже модель тем ее тяжелее обучить\n",
    "<br/>\n",
    "<font color=blue size=5>\n",
    "Глубокая модель должна работать не хуже, чем мелкая модель\n",
    "<br/><br/>\n",
    "Решение - скопировать обученные слои из мелкой модели, <br/> а дополнительные слои установить как identity mapping\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ResNet](./img/ResNet05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color=blue size=4>Заставляем блоки сети учить не H(x), а F(x)</font></center><br/>\n",
    "$$ F(x) = H(x) - x $$\n",
    "<center><font color=blue size=4>Предположение, что блоку легче выучить мапирование в 0 чем если X менять не нужно, чем отмапировать сам X</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Архитектуры ResNet - ов\n",
    "![ResNet](./img/ResNet06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Код резнет блока"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet-50+ используют  “bottleneck”  слои как в GoogLeNet\n",
    "![ResNet](./img/ResNet07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Код \"bottleneck\" блока"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренировка ResNet :\n",
    "- Batch Normalization после каждой свертки ( CONV layer )\n",
    "- SGD + Momentum (0.9)\n",
    "- Learning rate: 0.1, уменьшался в 10 когда обучение выходило на плато\n",
    "- Размер Mini-batch = 256\n",
    "- Weight decay of 1e-5 (l2-регуляризация)\n",
    "- Dropout не использовался\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ResNet](./img/ResNet08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Подбор правильного коэффициента обучения и уменьшение в процессе обучения\n",
    "![ResNet](./img/ResNet09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Пара методов для уменьшения LR \n",
    "1.  $$ lr_t = lr_{0} * (0.1 ^  { (epoch / 30)} ) $$\n",
    "2.  $$ lr_t = lr_{0} / (1 +  (epoch * lr_{decay} ) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73728"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*64*3*3 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69632\n"
     ]
    }
   ],
   "source": [
    "print(256*64*1 + 64*64*3*3 + 64*256*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(256*256*3*3 * 2) / (64*64*3*3 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "    lr_decay_step = 100\n",
    "    lr_decay      = 0.1\n",
    "    lr            = 0.1\n",
    "    \n",
    "hp = Hyperparams()\n",
    "# Экспоненциальное уменьшение коэффициента обучения\n",
    "def adjust_learning_rate_exp(optimizer, epoch):\n",
    "    \n",
    "    lr = hp.lr * ( hp.lr_decay ** (epoch // hp.lr_decay_step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr\n",
    "\n",
    "# Обратно пропорциональное уменьшение коэффициента обучение\n",
    "def adjust_learning_rate_inv(optimizer, epoch):\n",
    "    \n",
    "    lr = hp.lr / (1+epoch * hp.lr_decay)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Пинок LR\n",
    "![ResNet](./img/ResNet10.png)\n",
    "<font color=blue size=5>Как правило, модель в процессе обучения сходится в пространстве весов к одному из локальных минимумов </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ResNet](./img/noaa_blog1_3-768x695.png)\n",
    "<font color=blue size=5>Чтобы перейти в новый локальный минимум, увеличиваем LR и даем весам разойтись </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=10 color=blue> ResNet </font>\n",
    "### _ [He et al., 2015] _\n",
    "![ResNet](./img/ResNet11.png)\n",
    "<font color=blue size=5>\n",
    "Победитель ILSVRC'2015 (3.6% top 5 error) -- что лучше чем оценка человека! </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ResNet](./img/Perf01.png)\n",
    "<font color=blue size=5>\n",
    "Анализ моделей глубоких сетей</font>\n",
    "\n",
    "_ AN ANALYSIS OF DEEP NEURAL NETWORK MODELS FOR PRACTICAL APPLICATIONS [ Alfredo Canziani, Adam Paszke, Eugenio Culurciello, 2017] _ \n",
    "\n",
    "- Inception-v4: Resnet + Inception!\n",
    "- VGG: Больше памяти, и вычислений\n",
    "- GoogLeNet наиболее эффективная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ResNet](./img/Perf02.png)\n",
    "<font color=blue size=5>\n",
    "Анализ производительности предсказаний и энергопотребления для моделей глубоких сетей</font>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbpresent": {
   "slides": {
    "0317d5d1-f69c-4315-b055-b87228b8eda2": {
     "id": "0317d5d1-f69c-4315-b055-b87228b8eda2",
     "prev": "152a1e56-4918-43a9-ab8c-5ce9fc297569",
     "regions": {
      "0ccfcd6d-f2e7-4032-aacd-5a765100aa3e": {
       "attrs": {
        "height": 0.5817528847202887,
        "width": 0.41600215615472097,
        "x": 0.1,
        "y": 0.3182471152797112
       },
       "content": {
        "cell": "750c9e2a-9edb-49b1-ace4-a174a35685dd",
        "part": "whole"
       },
       "id": "0ccfcd6d-f2e7-4032-aacd-5a765100aa3e"
      },
      "481df643-37b8-4c39-80c2-27c6f67e0ffc": {
       "attrs": {
        "height": 0.2751436704964973,
        "width": 0.38044180914422987,
        "x": 0.5195581908557703,
        "y": 0.1
       },
       "content": {
        "cell": "8487f843-9969-4968-a244-cd6e5ceaeeb3",
        "part": "whole"
       },
       "id": "481df643-37b8-4c39-80c2-27c6f67e0ffc"
      },
      "8e5009b4-12f3-477d-9289-61ca8af3bf5d": {
       "attrs": {
        "height": 0.1977011370069829,
        "width": 0.4,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7a40228a-b38d-4b5f-a72d-9364a787241d",
        "part": "whole"
       },
       "id": "8e5009b4-12f3-477d-9289-61ca8af3bf5d"
      },
      "b5fe7c5e-9132-4187-b7a3-53aa8e775219": {
       "attrs": {
        "height": 0.4,
        "width": 0.38133081781949213,
        "x": 0.5204449632688264,
        "y": 0.3768430558429894
       },
       "content": {
        "cell": "3dc9b4b4-0709-493c-b5d7-d3b93d132ddc",
        "part": "whole"
       },
       "id": "b5fe7c5e-9132-4187-b7a3-53aa8e775219"
      }
     }
    },
    "152a1e56-4918-43a9-ab8c-5ce9fc297569": {
     "id": "152a1e56-4918-43a9-ab8c-5ce9fc297569",
     "prev": "fef004fe-e4d7-4813-bcec-a4c5c1ac2fd8",
     "regions": {
      "ec4eeed3-fa08-4721-af78-b35e5d245b69": {
       "attrs": {
        "height": 0.8640804521801886,
        "width": 0.7990840383309434,
        "x": 0.09956897268915653,
        "y": 0.09956897087575362
       },
       "content": {
        "cell": "76400926-921d-433e-96e2-d10052b90b88",
        "part": "whole"
       },
       "id": "ec4eeed3-fa08-4721-af78-b35e5d245b69"
      }
     }
    },
    "268e9440-96b5-4b83-9e4f-14e33d13ac67": {
     "id": "268e9440-96b5-4b83-9e4f-14e33d13ac67",
     "prev": "636b3ca4-f4ce-4467-b934-7e0acfdb99bb",
     "regions": {
      "2c2528e3-2df0-4bcc-8a1d-5b23516443d4": {
       "attrs": {
        "height": 0.1976816093274397,
        "width": 0.4160021561547211,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7a40228a-b38d-4b5f-a72d-9364a787241d",
        "part": "whole"
       },
       "id": "2c2528e3-2df0-4bcc-8a1d-5b23516443d4"
      },
      "35e0b571-2e4a-496d-be20-13717464144f": {
       "attrs": {
        "height": 0.5819165361509576,
        "width": 0.4162577278219023,
        "x": 0.1,
        "y": 0.3180834638490424
       },
       "content": {
        "cell": "750c9e2a-9edb-49b1-ace4-a174a35685dd",
        "part": "whole"
       },
       "id": "35e0b571-2e4a-496d-be20-13717464144f"
      },
      "40cf972a-f8ad-45a4-9d87-fc5504b230c3": {
       "attrs": {
        "height": 0.14870688112586158,
        "width": 0.3860726569266955,
        "x": 0.5165943690990914,
        "y": 0.3387930935524396
       },
       "content": {
        "cell": "579bf115-dcf3-4688-ae5a-a2b961d1e51b",
        "part": "whole"
       },
       "id": "40cf972a-f8ad-45a4-9d87-fc5504b230c3"
      },
      "d7cb20a9-cfda-45e4-b7fd-25f3739402a2": {
       "attrs": {
        "height": 0.23721263368530657,
        "width": 0.38516849919436236,
        "x": 0.5166095181561623,
        "y": 0.09999999999999998
       },
       "content": {
        "cell": "b91020bf-46f8-45d6-971e-671135c36183",
        "part": "whole"
       },
       "id": "d7cb20a9-cfda-45e4-b7fd-25f3739402a2"
      }
     }
    },
    "3fb0dd92-d910-4cbc-adcf-1fb2eafc52ad": {
     "id": "3fb0dd92-d910-4cbc-adcf-1fb2eafc52ad",
     "prev": "0317d5d1-f69c-4315-b055-b87228b8eda2",
     "regions": {
      "2dae7fa7-da45-4c3d-99d7-d14de66f480c": {
       "attrs": {
        "height": 0.8793842938260896,
        "width": 0.7993712278372316,
        "x": 0.1001043912873124,
        "y": 0.09956897087575362
       },
       "content": {
        "cell": "255f2ee6-b728-42d9-aa1c-b5a8e09cfa4f",
        "part": "whole"
       },
       "id": "2dae7fa7-da45-4c3d-99d7-d14de66f480c"
      }
     }
    },
    "636b3ca4-f4ce-4467-b934-7e0acfdb99bb": {
     "id": "636b3ca4-f4ce-4467-b934-7e0acfdb99bb",
     "prev": "d8c46a76-d507-41b0-a64a-9caa236c8bcf",
     "regions": {
      "4d8649a2-f7bb-4d33-96ba-2f3f587cc9b4": {
       "attrs": {
        "height": 0.07284480750348019,
        "width": 0.4,
        "x": 0.5,
        "y": 0.362356337944069
       },
       "content": {
        "cell": "d60fb6e4-b096-421a-9c34-79d41eeef7cd",
        "part": "whole"
       },
       "id": "4d8649a2-f7bb-4d33-96ba-2f3f587cc9b4"
      },
      "50d105ac-6778-48e1-b7d8-d1ab70ecb95e": {
       "attrs": {
        "height": 0.21997122876220884,
        "width": 0.39994610291457106,
        "x": 0.0999999660870103,
        "y": 0.3594253180140106
       },
       "content": {
        "cell": "01834b53-10cc-41f6-8097-436f6448ac2c",
        "part": "whole"
       },
       "id": "50d105ac-6778-48e1-b7d8-d1ab70ecb95e"
      },
      "5715ded6-9cd2-41dc-b864-5e94bf243601": {
       "attrs": {
        "height": 0.06336204830068251,
        "width": 0.4,
        "x": 0.1,
        "y": 0.2899999999999998
       },
       "content": {
        "cell": "52625045-43c1-40b9-a460-c6bf3afc3682",
        "part": "whole"
       },
       "id": "5715ded6-9cd2-41dc-b864-5e94bf243601"
      },
      "c4569e4f-89cb-4311-8078-c6c1846f7ac6": {
       "attrs": {
        "height": 0.107614924580405,
        "width": 0.4,
        "x": 0.5,
        "y": 0.42999999999999994
       },
       "content": {
        "cell": "f753c88c-d584-4bdf-9d6e-8329e8b1aa13",
        "part": "whole"
       },
       "id": "c4569e4f-89cb-4311-8078-c6c1846f7ac6"
      },
      "d7050ee1-2bd1-4290-9455-4b65d9816b6d": {
       "attrs": {
        "height": 0.18347699820278637,
        "width": 0.4,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9c53eb4c-ecef-47d0-855c-edb8f18be86c",
        "part": "whole"
       },
       "id": "d7050ee1-2bd1-4290-9455-4b65d9816b6d"
      }
     }
    },
    "b83b053a-d5b6-4bf3-9e77-30efc42648f0": {
     "id": "b83b053a-d5b6-4bf3-9e77-30efc42648f0",
     "layout": "manual",
     "prev": "ee2f137a-8043-4d58-8cda-25589fc83f1a",
     "regions": {
      "02904447-8289-4918-89aa-46607c573740": {
       "attrs": {
        "height": 0.33376433919578097,
        "width": 0.512850197890283,
        "x": 0.3907058368107662,
        "y": 0.06522988292307522
       },
       "content": {
        "cell": "8487f843-9969-4968-a244-cd6e5ceaeeb3",
        "part": "whole"
       },
       "id": "02904447-8289-4918-89aa-46607c573740",
       "y": 0.061
      },
      "2eef63e4-e9e1-41d4-81ce-7ef77fcefbb0": {
       "attrs": {
        "height": 0.09252872903495972,
        "width": 0.20975214349387153,
        "x": 0.10622306072683596,
        "y": 0.27385055162235866
       },
       "content": {
        "cell": "d8551909-4de7-4768-98e3-b750586a6c29",
        "part": "whole"
       },
       "id": "2eef63e4-e9e1-41d4-81ce-7ef77fcefbb0",
       "x": 0.106
      },
      "313e862f-a734-43e3-bfca-adf1ac4d847a": {
       "attrs": {
        "height": 0.15272985760137625,
        "width": 0.27548488159525353,
        "x": 0.10622306072683602,
        "y": 0.06623562704195388
       },
       "content": {
        "cell": "21bb4bca-732c-4b4c-8848-53fac30d3b9a",
        "part": "whole"
       },
       "id": "313e862f-a734-43e3-bfca-adf1ac4d847a",
       "y": 0.067
      },
      "48905e85-50c7-49c7-a3cb-f0bd32c91ff1": {
       "attrs": {
        "height": 0.5318965720979186,
        "width": 0.4026670260257866,
        "x": 0.1061691297284174,
        "y": 0.41818964032865913
       },
       "content": {
        "cell": "240a6b20-79d9-4d38-91ff-ee8e83bb4d99",
        "part": "whole"
       },
       "id": "48905e85-50c7-49c7-a3cb-f0bd32c91ff1",
       "x": 0.106
      },
      "b6c4d2ab-338f-4f22-b6c1-70b876ff09ce": {
       "attrs": {
        "height": 0.5281609028531334,
        "width": 0.3892779920288257,
        "x": 0.522279120749584,
        "y": 0.41767243329372217
       },
       "content": {
        "cell": "49639861-3403-4f98-a80a-9a8395acb0a9",
        "part": "whole"
       },
       "id": "b6c4d2ab-338f-4f22-b6c1-70b876ff09ce"
      }
     }
    },
    "d8c46a76-d507-41b0-a64a-9caa236c8bcf": {
     "id": "d8c46a76-d507-41b0-a64a-9caa236c8bcf",
     "layout": "manual",
     "prev": "b83b053a-d5b6-4bf3-9e77-30efc42648f0",
     "regions": {
      "04db2e0d-cddc-416b-94fc-9d3ffd94ce31": {
       "attrs": {
        "height": 0.16307467354542288,
        "width": 0.4497305819466608,
        "x": 0.5107233352540143,
        "y": 0.42204025947554835
       },
       "content": {
        "cell": "26ffbef3-cbd4-478e-b949-3a41bf576e03",
        "part": "whole"
       },
       "id": "04db2e0d-cddc-416b-94fc-9d3ffd94ce31"
      },
      "5100353c-9531-4463-8ce5-dcd6852d9017": {
       "attrs": {
        "height": 0.1061781183286368,
        "width": 0.44973058194666093,
        "x": 0.05021551418531224,
        "y": 0.47985634638463515
       },
       "content": {
        "cell": "724e2b08-9285-48c1-a151-f62f04cb3538",
        "part": "whole"
       },
       "id": "5100353c-9531-4463-8ce5-dcd6852d9017",
       "width": 0.45
      },
      "5cd34517-9a53-4b2d-9e7b-df95e9044868": {
       "attrs": {
        "height": 0.11408041766430163,
        "width": 0.44973058872925886,
        "x": 0.5116110098638387,
        "y": 0.6596264803426927
       },
       "content": {
        "cell": "759b05a9-3e0d-4d5f-be90-8e4518551e95",
        "part": "whole"
       },
       "id": "5cd34517-9a53-4b2d-9e7b-df95e9044868"
      },
      "5f5eb032-5a17-4721-8261-7923f88c6322": {
       "attrs": {
        "height": 0.23735628730067124,
        "width": 0.45,
        "x": 0.05,
        "y": 0.08000000000000002
       },
       "content": {
        "cell": "979d4d85-faaa-4ed0-a0bd-120283a4a602",
        "part": "whole"
       },
       "id": "5f5eb032-5a17-4721-8261-7923f88c6322"
      },
      "7885bd2a-0872-4ff3-8e79-c820617fa961": {
       "attrs": {
        "height": 0.185201111685284,
        "width": 0.4497305819466608,
        "x": 0.5116110166464367,
        "y": 0.08000000000000002
       },
       "content": {
        "cell": "db2d1a55-5ea6-48c8-bff4-61d5f2879a06",
        "part": "whole"
       },
       "id": "7885bd2a-0872-4ff3-8e79-c820617fa961"
      },
      "9a3cd05a-41c4-4700-b8e3-0d2fff7931b1": {
       "attrs": {
        "height": 0.06350570191604717,
        "width": 0.44973058194666093,
        "x": 0.5116110166464366,
        "y": 0.8591667144965425
       },
       "content": {
        "cell": "d86e1861-59dd-4193-b17a-09396fcf7011",
        "part": "whole"
       },
       "id": "9a3cd05a-41c4-4700-b8e3-0d2fff7931b1"
      },
      "cfb13f6e-aeb3-4524-901a-40033e634bfc": {
       "attrs": {
        "height": 0.13462639593702974,
        "width": 0.45,
        "x": 0.05016161031728522,
        "y": 0.33129311887413837
       },
       "content": {
        "cell": "e3c3cea8-397e-46e1-94d6-199e591ee243",
        "part": "whole"
       },
       "id": "cfb13f6e-aeb3-4524-901a-40033e634bfc"
      },
      "d63f5d3b-9a82-4ab1-91e2-ca04b703ad76": {
       "attrs": {
        "height": 0.129885016335631,
        "width": 0.4497305887292588,
        "x": 0.5116110098638387,
        "y": 0.2801149499021039
       },
       "content": {
        "cell": "f0812b32-2f30-4867-a40d-030b4d52e1a7",
        "part": "whole"
       },
       "id": "d63f5d3b-9a82-4ab1-91e2-ca04b703ad76"
      },
      "de6e5cb0-dfc6-40b7-8174-d94e993aaf4a": {
       "attrs": {
        "height": 0.05560340258038235,
        "width": 0.449730581946661,
        "x": 0.5116110166464366,
        "y": 0.5932471659231088
       },
       "content": {
        "cell": "144808c5-251b-40f3-b169-5c22bab1e1d9",
        "part": "whole"
       },
       "id": "de6e5cb0-dfc6-40b7-8174-d94e993aaf4a"
      },
      "e3c13331-1b7e-4a58-aa8e-dbf182a83e2d": {
       "attrs": {
        "height": 0.08247122032164261,
        "width": 0.4497305819466608,
        "x": 0.05021551418531224,
        "y": 0.5999712962867392
       },
       "content": {
        "cell": "7dff99b5-c1c9-4dcd-9fb7-ccdac2d1348e",
        "part": "whole"
       },
       "id": "e3c13331-1b7e-4a58-aa8e-dbf182a83e2d"
      },
      "e77b9bc3-756a-47d2-9069-c90098cb3d91": {
       "attrs": {
        "height": 0.2231321484964748,
        "width": 0.44973058872925886,
        "x": 0.050215487054920335,
        "y": 0.6995402679161148
       },
       "content": {
        "cell": "5d8b0226-396e-4193-93cc-9cd6a9609665",
        "part": "whole"
       },
       "id": "e77b9bc3-756a-47d2-9069-c90098cb3d91"
      },
      "ee549d8a-a451-4907-9e16-251c2f8ea753": {
       "attrs": {
        "height": 0.06350570191604744,
        "width": 0.4497305819466608,
        "x": 0.5116110166464367,
        "y": 0.783304640874161
       },
       "content": {
        "cell": "fa936582-9e45-4590-8356-81ea80631852",
        "part": "whole"
       },
       "id": "ee549d8a-a451-4907-9e16-251c2f8ea753"
      }
     }
    },
    "ec910fc7-22a1-4d46-abeb-13636155fbc9": {
     "id": "ec910fc7-22a1-4d46-abeb-13636155fbc9",
     "prev": "268e9440-96b5-4b83-9e4f-14e33d13ac67",
     "regions": {
      "2eab906d-9559-4444-a98e-729b4ec030be": {
       "attrs": {
        "height": 0.5817528847202887,
        "width": 0.4160021561547211,
        "x": 0.1,
        "y": 0.31824711527971117
       },
       "content": {
        "cell": "750c9e2a-9edb-49b1-ace4-a174a35685dd",
        "part": "whole"
       },
       "id": "2eab906d-9559-4444-a98e-729b4ec030be"
      },
      "5b5f37d7-9218-4ffd-9507-5071343e198e": {
       "attrs": {
        "height": 0.1989933493718647,
        "width": 0.41786262163266746,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7a40228a-b38d-4b5f-a72d-9364a787241d",
        "part": "whole"
       },
       "id": "5b5f37d7-9218-4ffd-9507-5071343e198e"
      },
      "a46db093-73d6-4627-b6b7-f031784f775f": {
       "attrs": {
        "height": 0.1076149245804049,
        "width": 0.38399784384527896,
        "x": 0.5168911648299832,
        "y": 0.4004310283706244
       },
       "content": {
        "cell": "da1d5f0f-0706-47c3-9421-d874a4e18185",
        "part": "whole"
       },
       "id": "a46db093-73d6-4627-b6b7-f031784f775f"
      },
      "db21bd22-0127-43cc-b7ac-099cd7a16425": {
       "attrs": {
        "height": 0.3241379263776187,
        "width": 0.3831088351700167,
        "x": 0.5168911648299833,
        "y": 0.1
       },
       "content": {
        "cell": "c5bc43d7-f8cb-4630-b559-fd423b1f0933",
        "part": "whole"
       },
       "id": "db21bd22-0127-43cc-b7ac-099cd7a16425"
      }
     }
    },
    "ee2f137a-8043-4d58-8cda-25589fc83f1a": {
     "id": "ee2f137a-8043-4d58-8cda-25589fc83f1a",
     "prev": null,
     "regions": {
      "047e8916-c55f-4bcf-a6a5-a467788c9bd5": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "bd994109-fd08-43a8-a495-fef77402af6e",
        "part": "whole"
       },
       "id": "047e8916-c55f-4bcf-a6a5-a467788c9bd5"
      },
      "f90f69e9-f597-4625-ad4e-a738e66d36f3": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "id": "f90f69e9-f597-4625-ad4e-a738e66d36f3"
      }
     }
    },
    "fef004fe-e4d7-4813-bcec-a4c5c1ac2fd8": {
     "id": "fef004fe-e4d7-4813-bcec-a4c5c1ac2fd8",
     "prev": "ec910fc7-22a1-4d46-abeb-13636155fbc9",
     "regions": {
      "195e821a-8e8b-41b3-a9e2-b4bbabbaf217": {
       "attrs": {
        "height": 0.5201149499021038,
        "width": 0.4160021561547211,
        "x": 0.09999999999999999,
        "y": 0.31560343634264776
       },
       "content": {
        "cell": "750c9e2a-9edb-49b1-ace4-a174a35685dd",
        "part": "whole"
       },
       "id": "195e821a-8e8b-41b3-a9e2-b4bbabbaf217"
      },
      "af4dc7c2-f781-4113-ba37-1b4e8e8b0b8e": {
       "attrs": {
        "height": 0.3035919481048903,
        "width": 0.38577586119580354,
        "x": 0.5168911648299833,
        "y": 0.09999999999999998
       },
       "content": {
        "cell": "399c7dac-db77-4946-a693-884587f29b5d",
        "part": "whole"
       },
       "id": "af4dc7c2-f781-4113-ba37-1b4e8e8b0b8e"
      },
      "be9d4a64-f16c-4269-89cd-2cbdea43358c": {
       "attrs": {
        "height": 0.12341952325173446,
        "width": 0.3857758611958034,
        "x": 0.5168553281933008,
        "y": 0.3972063990600338
       },
       "content": {
        "cell": "da1d5f0f-0706-47c3-9421-d874a4e18185",
        "part": "whole"
       },
       "id": "be9d4a64-f16c-4269-89cd-2cbdea43358c"
      },
      "d77859b9-5a27-49f0-bd6d-026d545257aa": {
       "attrs": {
        "height": 0.19943020804645686,
        "width": 0.41778017350524566,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7a40228a-b38d-4b5f-a72d-9364a787241d",
        "part": "whole"
       },
       "id": "d77859b9-5a27-49f0-bd6d-026d545257aa"
      }
     }
    }
   },
   "themes": {
    "default": "1fdde4ad-5a75-4abc-bc41-6f21e05aaacb",
    "theme": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
